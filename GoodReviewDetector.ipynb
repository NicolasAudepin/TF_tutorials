{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', '']\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "dataFolder = \"C:\\\\Users\\\\AUDEPIN\\\\Documents\\\\DataSet\\\\aclImdb-movie-review\\\\\"\n",
    "posFolder  = \"C:\\\\Users\\\\AUDEPIN\\\\Documents\\\\DataSet\\\\aclImdb-movie-review\\\\train\\\\pos\\\\\"\n",
    "negFolder  = \"C:\\\\Users\\\\AUDEPIN\\\\Documents\\\\DataSet\\\\aclImdb-movie-review\\\\train\\\\neg\\\\\"\n",
    "\n",
    "voc = open(dataFolder + \"vocab.txt\", encoding=\"utf8\")\n",
    "liste = [line.split('\\n') for line in voc.readlines()]\n",
    "print(liste[0])\n",
    "IndexToWord = [line[0] for line in liste]\n",
    "print(IndexToWord[0])\n",
    "\n",
    "WordToIndex = {}\n",
    "n = len(IndexToWord)\n",
    "\n",
    "for i in range(n) :\n",
    "    WordToIndex[IndexToWord[i]] = i\n",
    "#print(WordToIndex)\n",
    "#print(voc.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n",
      "17800\n",
      "17900\n",
      "18000\n",
      "18100\n",
      "18200\n",
      "18300\n",
      "18400\n",
      "18500\n",
      "18600\n",
      "18700\n",
      "18800\n",
      "18900\n",
      "19000\n",
      "19100\n",
      "19200\n",
      "19300\n",
      "19400\n",
      "19500\n",
      "19600\n",
      "19700\n",
      "19800\n",
      "19900\n",
      "20000\n",
      "20100\n",
      "20200\n",
      "20300\n",
      "20400\n",
      "20500\n",
      "20600\n",
      "20700\n",
      "20800\n",
      "20900\n",
      "21000\n",
      "21100\n",
      "21200\n",
      "21300\n",
      "21400\n",
      "21500\n",
      "21600\n",
      "21700\n",
      "21800\n",
      "21900\n",
      "22000\n",
      "22100\n",
      "22200\n",
      "22300\n",
      "22400\n",
      "22500\n",
      "22600\n",
      "22700\n",
      "22800\n",
      "22900\n",
      "23000\n",
      "23100\n",
      "23200\n",
      "23300\n",
      "23400\n",
      "23500\n",
      "23600\n",
      "23700\n",
      "23800\n",
      "23900\n",
      "24000\n",
      "24100\n",
      "24200\n",
      "24300\n",
      "24400\n",
      "24500\n",
      "24600\n",
      "24700\n",
      "24800\n",
      "24900\n",
      "25000\n"
     ]
    }
   ],
   "source": [
    "revLength = 400\n",
    "vocabSize = 2000\n",
    "\n",
    "dataSet=[]\n",
    "truthSet=[]\n",
    "foldlist= [posFolder,negFolder]\n",
    "n=0\n",
    "for fold in foldlist:\n",
    "    directory = os.fsencode(fold)\n",
    "    for fileNamebytes in sorted(os.listdir(directory)):\n",
    "        n=n+1\n",
    "        if (n%100 == 0):\n",
    "            print(n)\n",
    "        if (fold == posFolder):\n",
    "            truthSet.append(1)\n",
    "        else:\n",
    "            truthSet.append(0)\n",
    "        \n",
    "        fileName = fileNamebytes.strip().decode('utf-8')\n",
    "        review = open(fold+fileName, encoding = \"utf8\")\n",
    "        revList = [word.split(' ') for word in review.readlines()]\n",
    "\n",
    "        revIndex = []\n",
    "        for i in range(revLength):\n",
    "            if i<len(revList[0]):\n",
    "                if  (revList[0][i] in WordToIndex): \n",
    "                    wordVal = min(WordToIndex[revList[0][i]],vocabSize)\n",
    "                else:\n",
    "                    wordVal = 0\n",
    "            else:\n",
    "                wordVal = 0\n",
    "            revIndex.append(wordVal)\n",
    "        dataSet.append(revIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataSet))\n",
    "for i in range(len(dataSet)-1):\n",
    "    j=randint(0,len(dataSet))\n",
    "    \n",
    "    data = dataSet[i]\n",
    "    truth = truthSet[i]\n",
    "    dataSet[i]=dataSet[j]\n",
    "    truthSet[i]=truthSet[j]\n",
    "    dataSet[j]=data\n",
    "    truthSet[j]=truth\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "#print(dataSet[0])\n",
    "#print(truthSet)\n",
    "print(len(dataSet))\n",
    "print(len(dataSet[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_20 (Embedding)     (None, None, 8)           48008     \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 4)                 208       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 48,221\n",
      "Trainable params: 48,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "wordDim=8\n",
    "LSTNN = k.Sequential()\n",
    "LSTNN.add(k.layers.Embedding(vocabSize+1,wordDim))\n",
    "LSTNN.add(k.layers.LSTM(4, input_shape=(None,revLength,wordDim)))\n",
    "LSTNN.add(k.layers.Dropout(0.5))\n",
    "#RNN.add(keras.layers.GlobalAveragePooling1D())\n",
    "#RNN.add(k.layers.Dense(4, activation = tf.nn.relu))\n",
    "LSTNN.add(k.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "\n",
    "LSTNN.summary()\n",
    "\n",
    "\n",
    "LSTNN.compile(optimizer = 'adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_21 (Embedding)     (None, None, 8)           48008     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_2 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 48,121\n",
      "Trainable params: 48,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wordDim=8\n",
    "DNN = k.Sequential()\n",
    "DNN.add(k.layers.Embedding(vocabSize+1,wordDim))\n",
    "DNN.add(k.layers.GlobalAveragePooling1D())\n",
    "DNN.add(k.layers.Dense(8, activation = tf.nn.relu))\n",
    "DNN.add(k.layers.Dense(4, activation = tf.nn.relu))\n",
    "DNN.add(k.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "\n",
    "DNN.summary()\n",
    "\n",
    "\n",
    "DNN.compile(optimizer = 'adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = k.Sequential()\n",
    "model.add(k.layers.Embedding(vocabSize+1, output_dim=64))\n",
    "model.add(k.layers.LSTM(8))\n",
    "model.add(k.layers.Dropout(0.2))\n",
    "model.add(k.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "a=15000\n",
    "\n",
    "trainData = [dataSet[:a]]\n",
    "trainTruth = truthSet[:a]\n",
    "\n",
    "valData = [dataSet[a:]]\n",
    "valTruth = truthSet[a:]\n",
    "\n",
    "print(len(valTruth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_22 (Embedding)     (None, None, 8)           48008     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 48,121\n",
      "Trainable params: 48,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "wordDim=8\n",
    "DNN = k.Sequential()\n",
    "DNN.add(k.layers.Embedding(vocabSize+1,wordDim))\n",
    "DNN.add(k.layers.GlobalAveragePooling1D())\n",
    "DNN.add(k.layers.Dense(8, activation = tf.nn.relu))\n",
    "DNN.add(k.layers.Dense(4, activation = tf.nn.relu))\n",
    "DNN.add(k.layers.Dense(4, activation = tf.nn.relu))\n",
    "DNN.add(k.layers.Dense(1, activation = tf.nn.sigmoid))\n",
    "\n",
    "DNN.summary()\n",
    "\n",
    "\n",
    "DNN.compile(optimizer = 'adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_35 (Embedding)     (None, None, 8)           48008     \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_9 ( (None, 8)                 0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 48,101\n",
      "Trainable params: 48,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = k.Sequential()\n",
    "model.add(k.layers.Embedding(vocabSize+1, output_dim=8))\n",
    "#model.add(k.layers.LSTM(8,return_sequences=True ))\n",
    "#model.add(k.layers.Dropout(0.2))\n",
    "model.add(k.layers.GlobalAveragePooling1D())\n",
    "model.add(k.layers.Dense(8,activation = tf.nn.relu))\n",
    "#model.add(k.layers.Dense(64,activation = tf.nn.relu))\n",
    "model.add(k.layers.Dense(2,activation = tf.nn.relu))\n",
    "model.add(k.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(optimizer = 'adam',\n",
    "           loss = 'binary_crossentropy',\n",
    "           metrics =['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "15000/15000 [==============================] - 3s 216us/sample - loss: 0.6931 - acc: 0.5049 - val_loss: 0.6933 - val_acc: 0.4905\n",
      "Epoch 2/40\n",
      "15000/15000 [==============================] - 1s 95us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 3/40\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 4/40\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 5/40\n",
      "15000/15000 [==============================] - 1s 96us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 6/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 7/40\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 8/40\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 9/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 10/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 11/40\n",
      "15000/15000 [==============================] - 1s 100us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 12/40\n",
      "15000/15000 [==============================] - 1s 97us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 13/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 14/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 15/40\n",
      "15000/15000 [==============================] - 2s 101us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 16/40\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 17/40\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 18/40\n",
      "15000/15000 [==============================] - 2s 104us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 19/40\n",
      "15000/15000 [==============================] - 2s 101us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 20/40\n",
      "15000/15000 [==============================] - 1s 99us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 21/40\n",
      "15000/15000 [==============================] - 2s 100us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 22/40\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 23/40\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 24/40\n",
      "15000/15000 [==============================] - 2s 114us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 25/40\n",
      "15000/15000 [==============================] - 2s 101us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 26/40\n",
      "15000/15000 [==============================] - 2s 104us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 27/40\n",
      "15000/15000 [==============================] - 2s 102us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 28/40\n",
      "15000/15000 [==============================] - 2s 109us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 29/40\n",
      "15000/15000 [==============================] - 2s 108us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 30/40\n",
      "15000/15000 [==============================] - 2s 105us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 31/40\n",
      "15000/15000 [==============================] - 2s 111us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 32/40\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 33/40\n",
      "15000/15000 [==============================] - 2s 117us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 34/40\n",
      "15000/15000 [==============================] - 2s 106us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 35/40\n",
      "15000/15000 [==============================] - 2s 107us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6934 - val_acc: 0.4905\n",
      "Epoch 36/40\n",
      "15000/15000 [==============================] - 2s 107us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 37/40\n",
      "15000/15000 [==============================] - 2s 110us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 38/40\n",
      "15000/15000 [==============================] - 2s 108us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 39/40\n",
      "15000/15000 [==============================] - 2s 113us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n",
      "Epoch 40/40\n",
      "15000/15000 [==============================] - 2s 112us/sample - loss: 0.6931 - acc: 0.5063 - val_loss: 0.6935 - val_acc: 0.4905\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(trainData,trainTruth,\n",
    "                 epochs=40,\n",
    "                 batch_size=512,\n",
    "                 validation_data=(valData,valTruth),\n",
    "                 verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.6931764821688334, 0.6928425498962403, 0.6926649974822998, 0.6924382397015889, 0.6919111256281535, 0.6890298652331034, 0.681293011188507, 0.6932434080759684, 0.6899035301526387, 0.6792014169692994], 'acc': [0.5036, 0.5136667, 0.51426667, 0.5104, 0.5232, 0.5240667, 0.54473335, 0.51413333, 0.5337333, 0.53346664], 'val_loss': [0.6936212650299072, 0.6931164005279541, 0.6930483060836792, 0.6927729984283447, 0.6923497438430786, 0.6866079753875732, 0.6969911259651184, 0.6954576567649842, 0.6917709529876709, 0.6562140495300293], 'val_acc': [0.4906, 0.5035, 0.5058, 0.5065, 0.5063, 0.5254, 0.4965, 0.4978, 0.511, 0.5229]}\n"
     ]
    }
   ],
   "source": [
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotlist=[]\n",
    "plotname=['loss','acc','val_loss','val_acc']\n",
    "\n",
    "for name in plotname:\n",
    "    plotlist.append(history.history[name])\n",
    "\n",
    "epoch = range(1, len(plotlist[0])+1)\n",
    "    \n",
    "for i in range(len(plotlist)):\n",
    "    plt.plot(epoch, plotlist[i],label=plotname[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
